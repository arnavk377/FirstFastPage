{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing ML\n",
    "> Quick launch into Variables, Functions, Arrays, Classes, HTML.\n",
    "\n",
    "- layout: default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-16 09:38:20.994806: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10 images belonging to 3 classes.\n",
      "Found 0 images belonging to 3 classes.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-16 09:38:30.395749: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 6s 6s/step - loss: 1.0756 - accuracy: 0.6000\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.8388 - accuracy: 0.8000\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.6416 - accuracy: 0.8000\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.4779 - accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.3786 - accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.2976 - accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.2223 - accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.1663 - accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.1286 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.1013 - accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import certifi\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Set the paths to your dataset and tags\n",
    "dataset_path = '/Users/poonam/Desktop/imgdata'\n",
    "tags = ['animals', 'food', 'people']  # Replace with your own tags\n",
    "\n",
    "# Define the parameters for training the model\n",
    "image_size = (224, 224)\n",
    "batch_size = 32\n",
    "num_epochs = 10\n",
    "\n",
    "# Create data generators for training and validation\n",
    "data_generator = ImageDataGenerator(rescale=1.0/255.0, validation_split=0.2)\n",
    "train_generator = data_generator.flow_from_directory(dataset_path, target_size=image_size, batch_size=batch_size, subset='training')\n",
    "validation_generator = data_generator.flow_from_directory(dataset_path, target_size=image_size, batch_size=batch_size, subset='validation')\n",
    "\n",
    "# Set the SSL certificate file environment variable\n",
    "os.environ['SSL_CERT_FILE'] = certifi.where()\n",
    "\n",
    "# Load the pre-trained VGG16 model without the top classification layer\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(image_size[0], image_size[1], 3))\n",
    "\n",
    "# Add a global average pooling layer and a dense layer for classification\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "predictions = Dense(len(tags), activation='softmax')(x)\n",
    "\n",
    "# Create the model with the VGG16 base and the classification layers\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Freeze the weights of the pre-trained layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_generator, epochs=num_epochs, validation_data=validation_generator)\n",
    "\n",
    "# Save the trained model\n",
    "model.save('image_tagging_model.h5')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 902ms/step\n",
      "Image\n",
      "Predicted class: 2\n",
      "Predicted tag: people\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "\n",
    "# Load the saved model\n",
    "model = load_model('image_tagging_model.h5')\n",
    "\n",
    "# Load and preprocess the input image\n",
    "image_path = '/Users/poonam/Downloads/dwayne.jpeg'  # Replace with the path to your input image\n",
    "person = Image.open(image_path)\n",
    "img = image.load_img(image_path, target_size=(224, 224))\n",
    "img = image.img_to_array(img)\n",
    "img = np.expand_dims(img, axis=0)\n",
    "img = img / 255.0  # Normalize the image\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(img)\n",
    "predicted_class = np.argmax(predictions[0])  # Get the index of the highest probability class\n",
    "\n",
    "# Print the predicted class and corresponding tag\n",
    "tags = ['animals', 'food', 'people']  # Replace with your own tags\n",
    "predicted_tag = tags[predicted_class]\n",
    "print(\"Image\")\n",
    "person.show()\n",
    "print(\"Predicted class:\", predicted_class)\n",
    "print(\"Predicted tag:\", predicted_tag)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
